# -*- coding: utf-8 -*-
"""Dua_Asif_210701_AIproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l24qXQh3RW2SmV-_q-Oi8Xulp4AZuDzi

**Its a classification Problem**
"""

import pandas as pd
df = pd.read_csv('winequality-red.csv')
print("Data Head:")
print(df.head())
print("\nData Tail:")
print(df.tail())
print("\nData Shape:")
print("Number of rows:", df.shape[0])
print("Number of columns:", df.shape[1])
print("\nData Overview:")
print(df.info())

print("\nMissing Values:")
print(df.isnull().sum())

print("\nOutliers (using standard deviation):")
for col in df.select_dtypes(include=['number']):
    mean = df[col].mean()
    std = df[col].std()
    threshold = 3
    outliers = df[(df[col] < mean - threshold * std) | (df[col] > mean + threshold * std)]
    print(f"\nColumn: {col}")
    print(f"Number of outliers: {len(outliers)}")
    print("Outlier rows:")
    print(outliers)

"""Impact of Missing Values and Outliers:Missing values can lead to biased or inaccurate results if not handled properly."""

for col in df.columns:
    if df[col].isnull().any():
        if pd.api.types.is_numeric_dtype(df[col]):
            mean_val = df[col].mean()
            df[col].fillna(mean_val, inplace=True)
            print(f"Column '{col}' imputed with mean: {mean_val}")
        else:
            mode_val = df[col].mode()[0]
            df[col].fillna(mode_val, inplace=True)
            print(f"Column '{col}' imputed with mode: {mode_val}")
print("\nMissing Values after imputation:")
print(df.isnull().sum())

from sklearn.preprocessing import LabelEncoder, OneHotEncoder

categorical_features = df.select_dtypes(include=['object']).columns
numerical_features = df.select_dtypes(include=['number']).columns

print("\nCategorical Features:")
print(categorical_features)
print("\nNumerical Features:")
print(numerical_features)

"""**No categorical feature so one hot encoding is not required**"""

import pandas as pd

correlation_matrix = df.corr()
quality_correlations = correlation_matrix['quality'].drop('quality')
print("\nCorrelation with Quality:")
print(quality_correlations.abs().sort_values(ascending=False))

top_features = quality_correlations[quality_correlations.abs() > 0.2].index.tolist()

print("\nTop Features influencing wine quality (abs corr > 0.2):")
top_features

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df[numerical_features] = scaler.fit_transform(df[numerical_features])
print(df.head())

df['TotalAcidity'] = df['fixed acidity'] + df['volatile acidity'] + df['citric acid']
df['SulfurDioxideRatio'] = df['free sulfur dioxide'] / df['total sulfur dioxide']

"""
1. Total Acidity:

Derivation: Sum of fixed acidity, volatile acidity, and citric acid.
ah
2. Sulfur Dioxide Ratio

Derivation: Ratio of free sulfur dioxide to total sulfur dioxide.
"""

import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style("whitegrid")
plt.figure(figsize=(8, 6))
sns.histplot(df['quality'], bins=10, kde=True)
plt.title('Distribution of Wine Quality Ratings')
plt.xlabel('Quality Rating')
plt.ylabel('Frequency')
plt.show()

for col in ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']:
    plt.figure(figsize=(8, 6))
    sns.histplot(df[col], bins=20, kde=True)
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    plt.show()

for feature in top_features:
    plt.figure(figsize=(8, 6))
    sns.scatterplot(x=feature, y='quality', data=df)
    plt.title(f'Scatter Plot of {feature} vs. Wine Quality')
    plt.xlabel(feature)
    plt.ylabel('Quality')
    plt.show()

from sklearn.model_selection import train_test_split
X = df.drop('quality', axis=1)
y = df['quality']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train, y_train)
lr_pred = lr_model.predict(X_test)
print("Logistic Regression Accuracy:", accuracy_score(y_test, lr_pred))
print(classification_report(y_test, lr_pred))
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)
dt_pred = dt_model.predict(X_test)
print("\nDecision Tree Accuracy:", accuracy_score(y_test, dt_pred))
print(classification_report(y_test, dt_pred))

from sklearn.metrics import confusion_matrix

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
def plot_confusion_matrix(y_true, y_pred, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=sorted(df['quality'].unique()),
                yticklabels=sorted(df['quality'].unique()))
    plt.title(title)
    plt.xlabel("Predicted Label")
    plt.ylabel("True Label")
    plt.show()
plot_confusion_matrix(y_test, lr_pred, "Logistic Regression Confusion Matrix")
plot_confusion_matrix(y_test, dt_pred, "Decision Tree Confusion Matrix")
lr_cm = confusion_matrix(y_test, lr_pred)
lr_precision = precision_score(y_test, lr_pred, average='weighted')
lr_recall = recall_score(y_test, lr_pred, average='weighted')
lr_f1 = f1_score(y_test, lr_pred, average='weighted')
print("Logistic Regression Precision:", lr_precision)
print("Logistic Regression Recall:", lr_recall)
print("Logistic Regression F1-score:", lr_f1)
dt_cm = confusion_matrix(y_test, dt_pred)
dt_precision = precision_score(y_test, dt_pred, average='weighted')
dt_recall = recall_score(y_test, dt_pred, average='weighted')
dt_f1 = f1_score(y_test, dt_pred, average='weighted')
print('\n')
print("Decision Tree Precision:", dt_precision)
print("Decision Tree Recall:", dt_recall)
print("Decision Tree F1-score:", dt_f1)

"""
Decision Tree outperformed Logistic Regression:  Decision Tree achieved higher accuracy, precision, recall, and F1-score.

Decision Tree Strengths: Better at capturing non-linear relationships in the data, which might be present in the complex interactions of wine attributes affecting quality.  More accurately predicted the different quality classes.

Decision Tree Weaknesses:Prone to overfitting. The model might be too complex and may not generalize well to unseen data.

Logistic Regression Strengths: Simpler model, less prone to overfitting compared to Decision Tree.

Logistic Regression Weaknesses: Assumes a linear relationship between features and the target, which may not accurately represent the real-world relationships affecting wine quality."""